{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip-gram Implementation Project\n",
    "\n",
    "Welcome to my skip gram notebook! Here, we'll uncover the mystery behind word embeddings by building a skip-gram model from scratch and see why such a simple model can create such interesting results!\n",
    "\n",
    "## Introduction to Skip-gram\n",
    "\n",
    "The  Skip-Gram  model  introduced  an  efficient  and  intuitive  way  to  create  word embeddings  with  various  positive  qualities.  With this model you could find so many common relationships between words, just by considering the context words appear in. The context in this case, is simply whatever words are nearby in the text you use for training. \n",
    "<br><br>\n",
    "The model chooses to represet words as vectors that live in a high-dimensional space. These vectors are trained to be close to eachother if they typically appear in the same context, and far apart if they typically don't. This basically means they are a bunch of points, and the ones that are near to each other should be related words while the ones that are far apart should be unrelated.\n",
    "<br><br>\n",
    "Of course, the proper context for a given word must be learned in practice, such as in the transformer model, but the skip-gram model layed a smooth foundation for the expedited progress of natural language processing in the past 10 years.\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "In this project, our main goals are:\n",
    "\n",
    "\n",
    "1. **[Understanding Skip-gram](#understanding-skip-gram):** We will start by grasping the architecture of the skip-gram model along with its training objective. This will teach us how important a good training objective is and how it can create such fascinating results.\n",
    "\n",
    "2. **[Data Preprocessing](#data-preprocessing):** Before diving into the model implementation, we will prepare our data. This step involves cleaning and organizing the text data to ensure it meets the training objective.\n",
    "\n",
    "3. **[Model Implementation](#model-implementation):** We'll build the architecture as efficiently as we can, covering the output weights and the embeddings.\n",
    "    - **[Forward and Backward Passes](#forward-and-backward-passes):** With the model implemented, we'll train it using our processed dataset and evaluate its performance. We will learn together how training happens in this model and how gradients are propagated!\n",
    "<br><br>\n",
    "4. **[Visualization](#visualization):** To gain insights into the model's output, we'll visualize the word embeddings in a lower-dimensional space. We will also measure the predicted distribution across all words and see how it changes over time.\n",
    "\n",
    "5. **[Discussion](#discussion):** Lastly, we'll discuss the efficiency concerns of the model and the limitations in training both in this way and on such a limited dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"understanding-skip-gram\"></a>\n",
    "## Understanding Skip-gram\n",
    "***\n",
    "The skip-gram model takes in an emedding matrix, passes it through one layer and compares it to a target (the context). The embedding matrix is essentially all the word vectors we have, one per word, and we will select the current word vector based on the current word in the text. \n",
    "<br><br> The context is also a vector. It is has one value per word, and this value is 0 if the word is not in the context and 1 if it is.\n",
    "\n",
    "So if I had: \n",
    "- \"It is nice outside today\" and current word is \"nice\" \n",
    "- $\\rightarrow$ Get the word vector for \"nice\" from the embedding matrix\n",
    "- $\\rightarrow$ Pass it through the skip-gram model\n",
    "- $\\rightarrow$ Get output vector with values between (0, 1). 0 means not in context and 1 means in context.\n",
    "- $\\rightarrow$ Compare to ground truth (context) which has a 1 exactly where the surrounding words \"It\" \"is\" \"outside\" \"today\" are, and 0 everywhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-preprocessing\"></a>\n",
    "## Data Loading and Preprocessing \n",
    "***\n",
    "So, before I get ahead of myself, let's prepare the data. Here, we want to read in a corpus (text file). Ideally, this will be prepared with care so as to encourage good relationships by the model. In my case, since this is a refactor of my first implementation of this project, and GPT has since come out.......I'll ask it to give me a corpus that propotes semantically meaningful embeddings. I don't really know how its figuring that out, but if you're interested, I'll show a bit of it below.\n",
    "\n",
    "1. First we read the file line by line. \n",
    "2. Then we will process the data to remove punctuation, stopwords and split into words.\n",
    "    - We can use re to effeciently clean the punctuation and numbers from our text.\n",
    "    - NLTK provides a nice collection of stopwords we can install, so we use those to get rid of our stopwords.\n",
    "3. Lastly, we create our encoding, which maps our words to indices in our embedding matrix, so we can quickly choose the current word in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /mnt/c/Users/chris/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# for use in later visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def get_data(filename):\n",
    "    contents = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.read()\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def process_data(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    cleaned_text = text.strip()\n",
    "\n",
    "    words = cleaned_text.split(' ')\n",
    "    stop_words_removed = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    return stop_words_removed\n",
    "\n",
    "def display_text(text, words=None):\n",
    "    print('-'*6 + f'\\nCORPUS\\n' + '-'*6)\n",
    "    for i, line in enumerate(corpus.split('.')):\n",
    "        print(line)\n",
    "\n",
    "        if i > 5:\n",
    "            break\n",
    "\n",
    "    if words is not None:\n",
    "        print()\n",
    "        print('-'*5 + f'\\nWORDS\\n' + '-'*5)\n",
    "        print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/'\n",
    "FILE = 'corpus.txt'\n",
    "\n",
    "filename = DATA_DIR + FILE\n",
    "\n",
    "corpus = get_data(filename)\n",
    "words = process_data(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see some of the original corpus, versus our list of words after preprocessing our data for training. We remove all punctuation, and filter out the stopwords. It's a fairly basic preprocessing stage, but good enough for the purposes of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "CORPUS\n",
      "------\n",
      "In the heart of the bustling city, travelers gather to share stories of their adventures\n",
      " Each journey brings unique experiences and lessons, as explorers venture into uncharted territories\n",
      "\n",
      "\n",
      "High in the mountains, where the air is crisp and the landscapes breathtaking, hikers navigate winding trails, uncovering hidden gems amidst the wilderness\n",
      " The echo of footsteps resonates through the valleys, connecting those who seek solace in nature\n",
      "\n",
      "\n",
      "Along the coastline, waves kiss the shore, leaving behind a treasure trove of shells and secrets\n",
      " Sailors set sail on the vast sea, chasing the horizon with dreams of distant lands\n",
      " The ocean's expanse reflects the infinite possibilities of the world\n",
      "\n",
      "-----\n",
      "WORDS\n",
      "-----\n",
      "['heart', 'bustling', 'city', 'travelers', 'gather', 'share', 'stories', 'adventures', 'journey', 'brings']\n"
     ]
    }
   ],
   "source": [
    "display_text(corpus, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Class\n",
    "Now I will create an encoding for the words, so each word gets a unique index. Then I will create our embedding matrix as a randomly initialized matrix, with one vector for each word.\n",
    "- I mentioned we are using a high-dimensional vector for each word. \n",
    "- This dimensionality can be modified, as a hyper-parameter it's important to see how the dimensionality affects our performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer class is very simple, just getting the encodings for the words and maintaining the vocabulary\n",
    "class Tokenizer():\n",
    "    def __init__(self):\n",
    "        self.vocab = []\n",
    "        self.index_to_key = {}\n",
    "        self.key_to_index = {}\n",
    "    \n",
    "    def fit(self, words):\n",
    "        # get unique words\n",
    "        vocab = set(words)\n",
    "        # get index for each unique word and create forward and backward map\n",
    "        self.index_to_key = {i : word for i, word in enumerate(vocab)}\n",
    "        self.key_to_index = {word : i for i, word in enumerate(vocab)}\n",
    "        self.vocab = list(vocab)\n",
    "\n",
    "def encode_words(words, tokenizer):\n",
    "    # encode the words as their indices for training\n",
    "    encoding = [tokenizer.key_to_index[word] for word in words]\n",
    "\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "ENCODED WORDS\n",
      "--------------\n",
      "Words: ['heart', 'bustling', 'city', 'travelers', 'gather', 'share', 'stories', 'adventures', 'journey', 'brings']\n",
      "Encoding: [135, 76, 21, 89, 127, 122, 82, 71, 126, 105]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(words)\n",
    "encoding = encode_words(words, tokenizer)\n",
    "\n",
    "print('--------------'+'\\nENCODED WORDS\\n'+'--------------')\n",
    "print('Words:', words[:10])\n",
    "print('Encoding:', encoding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation\n",
    "For our training set, we need a specific format. On each iteration, we will take the current word as input, and try to predict the surrounding words as output. So our training data has one input (the current word index) and one output (the surrounding words). The surrounding words are within a \"window\" of our input. This \"window size\" is also a hyper-parameter and can be adjusted.<br><br>\n",
    "**Note:** The window size is the value of words we take in either direction, so the context is 2x the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot(context_id, vocab_size):\n",
    "    one_hot_vector = np.zeros(vocab_size)\n",
    "    one_hot_vector[context_id] = 1.0\n",
    "    \n",
    "    return one_hot_vector\n",
    "\n",
    "def create_dataset(encoding, tokenizer, window_size=2):\n",
    "    dataset = []\n",
    "    for i in range(len(encoding)):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(encoding), i + window_size + 1)\n",
    "\n",
    "        context = encoding[start:i]\n",
    "        context.extend(encoding[i+1:end])\n",
    "\n",
    "        # target = one_hot(context, tokenizer)\n",
    "        \n",
    "        dataset.append({\n",
    "            'input_id': encoding[i], \n",
    "            'context': [one_hot(context_id, len(tokenizer.vocab)) for context_id in context]\n",
    "        })\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_id': 10,\n",
       " 'context': [array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1.])]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_SIZE = 2\n",
    "\n",
    "dataset = create_dataset(encoding, tokenizer, window_size=WINDOW_SIZE)\n",
    "dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-implementation\"></a>\n",
    "## Embeddings and Model Architecutre\n",
    "***\n",
    "The model architecture is basically one weight matrix. This matrix has the dimensions (embedding_dim, vocab_size), and is often refered to as the output word vectors. This is because the output vectors which refer to each word in the context move closer together, providing their own relationships. Besides this we have our word embeddings. This will be a matrix of dimensions (vocab_size, embedding_dim), where each word in the vocab has its own vector of size (, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <div style=\"text-align: center;\"> -->\n",
    "<img src=\"../../imgs/skip-gram-architecture.png\" alt=\"Skip Gram Architecture\" width=\"400\" height=\"500\" style=\"border: 2px solid black; padding: 20px; background-color: white;\">\n",
    "<!-- </div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Note:** In the original implementation, the embedding is abstracted away, giving rise to two weight matrices instead of one. This is because the input is a one-hot vector of the current word, so by performing matrix multiplication we get a unique weight vector from the first weight matrix (our embedding / hidden layer). The embedding is simply a more efficient implementation, opting out of the multiplication for simple indexing.\n",
    "- **Also Note:** There are multiple output vectors! Don't worry, it's really pretty simple. Each context word gets assigned its own one-hot vector. When we multiply by the weight matrix to get our prediction, we simply compare the prediction against each context vector individually. We basically ask multiple times, do you think ***this*** word's related?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkipGramModel Class\n",
    "Alright, so implementing the model is next. Let's make a simple class to hold our relevant states, so we can update the parameters and keep everything tidy.\n",
    "- This class will hold the relevant parameters that the model should update during training. \n",
    "- This will contain our word vectors and our weights. \n",
    "- We also add fields for our callback, which store relevant information for later visualizations. \n",
    "    - This can be cool for getting an animated view of the training process!\n",
    "\n",
    "**Key Features:**\n",
    "1. Embedding and weight matrices\n",
    "    - The embedding matrix and weight matrix will be initialized randomly to have values between -1 and 1. \n",
    "    - It's important to keep these small, as large values will cause unpredictable behavior in the model and severly hinder training.\n",
    "2. SoftMax\n",
    "    - This is our activation function for the output. When we multiply our matrices together, we get a value for each word. A larger value implies the model is more confident that a given word is in the context.\n",
    "    - SoftMax normalizes this information, so that the entire vector becomes a probability distribution. This means that for each word, the model predicts the probability that the word is in the context.\n",
    "3. Loss function\n",
    "    - $E = -\\log{p(w_I)}$\n",
    "    - This simple equation takes the log probability of our predictions. There are various nice qualities about this, the most prominent being the ease of gradient descent calculations. \n",
    "    - This objective moves word vectors away from eachother if they don't appear in the same context and closer if they do.\n",
    "***\n",
    "<a id=\"forward-and-backward-passes\"></a>\n",
    "**Forward and Backward Passes:**\n",
    "1. Predict\n",
    "    - Performs the inner product of the matrices, giving us our prediction score.\n",
    "    - Takes the prediction scores and normalizes them into a probability distribution with softmax.\n",
    "2. Backward\n",
    "    - Gradient descent takes the negative gradient and shifts the weight in this direction. By taking the negative gradient, we are trying to ski down the loss function and minimize the error.\n",
    "    - This process can be broken down in three steps:\n",
    "        1. Gradient of the loss function: This simply evaluates to the 'prediction - truth.' \n",
    "        - The nice properties show up! The gradient of that seemingly complex loss function is just prediction score minus 1 (if the word is in the context) and minus 0 (if its not). \n",
    "        - **Notice** \n",
    "            - If our predicted probability is close to 1 and we are wrong, then we get a relatively large positive value. \n",
    "            - If we predict close to 0 we are wrong, we get a large negative value. \n",
    "            - By doing this we will bring vectors close if they are 1, and push them away if they are 0. This push is proportional to the error (how far off from the truth we were). \n",
    "            - If we are right, then the push is tiny, and we don't mess much with that prediction anymore.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel():\n",
    "    def __init__(self, vocab_size, embedding_dim, target_id=0, learning_rate=0.001):\n",
    "        self.embedding_matrix = np.random.uniform(-1, 1, (vocab_size, embedding_dim))\n",
    "        self.weights = np.random.uniform(-1, 1, (embedding_dim, vocab_size))\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.target_id=target_id\n",
    "\n",
    "        self.vectors_over_time = []\n",
    "        self.predictions_over_time = []\n",
    "        self.loss_curve = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(score):\n",
    "        exp_scores = np.exp(score - np.max(score))\n",
    "        return exp_scores / exp_scores.sum()\n",
    "    \n",
    "    def loss_fn(self, y_pred, context):\n",
    "        epsilon = 1e-8\n",
    "        loss = -np.sum(context * np.log(np.maximum(y_pred, epsilon)), axis=-1).mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    # for predictions, we perform an inner product with the weights, then softmax the score to get a distribution we compare to ground truth context\n",
    "    def predict(self, input_id):\n",
    "        try:    \n",
    "            score = np.dot(self.embedding_matrix[input_id], self.weights)\n",
    "            y_pred = SkipGramModel.softmax(score)\n",
    "        except:\n",
    "            print(input_id)\n",
    "            y_pred = np.zeros(self.embedding_matrix[input_id].shape)\n",
    "       \n",
    "        return y_pred\n",
    "\n",
    "    # backward pass transfers the gradient from the prediction error (y_pred - context)\n",
    "    # to the weights by performing an outer product with the current word embedding. \n",
    "    # this is then used to update the embedding vector by performing an inner product on the new weights with the error\n",
    "    def backward(self, input_id, context, y_pred):\n",
    "        for context_vector in context:\n",
    "            # Calculate the error as the difference between the prediction and the true context word\n",
    "            error = y_pred - context_vector\n",
    "            \n",
    "            # Update the output vectors (model weights)\n",
    "            self.weights -= self.learning_rate * np.outer(self.embedding_matrix[input_id], error)\n",
    "\n",
    "            # Update the input vectors (embedding vector)\n",
    "            self.embedding_matrix[input_id] -= self.learning_rate * np.dot(self.weights, error)\n",
    "\n",
    "    # updated when the model runs to get visualizations\n",
    "    def update_model_states(self, word_vectors_2d=None, predictions=None, loss=None):\n",
    "        if word_vectors_2d is not None:\n",
    "            self.vectors_over_time.append(word_vectors_2d)\n",
    "        if predictions is not None:\n",
    "            self.predictions_over_time.append(predictions)\n",
    "        if loss is not None:\n",
    "            self.loss_curve.append(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training\n",
    "The training is pretty straight-forward:\n",
    "1. Get a prediction\n",
    "2. Run the backward method to update the weights based on that prediction\n",
    "3. Repeat for each word\n",
    "4. Repeat steps (1-3) a ton of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "\n",
    "def train(model, training_data, epochs=100, verbose=True, reducer=None):\n",
    "    for epoch in range(epochs+1):\n",
    "        for sample in training_data:\n",
    "            # get our input word and its current context\n",
    "            input_id = sample['input_id']\n",
    "            context = np.array(sample['context'])\n",
    "            \n",
    "            # predict the context and get the loss\n",
    "            y_pred = model.predict(input_id)\n",
    "            loss = model.loss_fn(y_pred, context)\n",
    "\n",
    "            # update the weights and embeddings\n",
    "            model.backward(input_id, context, y_pred)\n",
    "\n",
    "        # every so often we add to our information about the model\n",
    "        if reducer and epoch % 10 == 0:\n",
    "            x = reducer.transform(model.embedding_matrix)\n",
    "            model.update_model_states(word_vectors_2d=x)\n",
    "        if epoch % 50 == 0 and verbose:\n",
    "            print(f\"Epoch: {epoch} - Loss: {loss}\")\n",
    "        \n",
    "        model.update_model_states(predictions=model.predict(model.target_id), loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train our model, and watch as the loss decreases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 6.837111938523112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 - Loss: 2.4795894954530038\n",
      "Epoch: 100 - Loss: 1.1723768066240334\n",
      "Epoch: 150 - Loss: 0.8456434358580166\n",
      "Epoch: 200 - Loss: 0.7758136305685568\n",
      "Epoch: 250 - Loss: 0.7485375409013222\n",
      "Epoch: 300 - Loss: 0.7343799704510923\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "EPOCHS = 300\n",
    "LR = 0.005\n",
    "TARGET_ID = tokenizer.key_to_index['treasure']\n",
    "\n",
    "model = SkipGramModel(\n",
    "    vocab_size=len(tokenizer.vocab), \n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    learning_rate=LR,\n",
    "    target_id=TARGET_ID\n",
    ")\n",
    "\n",
    "train(model, epochs=EPOCHS, training_data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added this to fix a bug I was having. If you fit_transform PCA on each iteration of updates, you will find different principal components, so the movement of vectors will not be smooth. Instead, a solution is to fit the PCA to the trained embeddings, then simply transform on a new training cycle to capture the vector movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 4.737538805736748\n",
      "Epoch: 50 - Loss: 2.415051070799252\n",
      "Epoch: 100 - Loss: 1.0921683293152449\n",
      "Epoch: 150 - Loss: 0.84741495015244\n",
      "Epoch: 200 - Loss: 0.7800437516620518\n",
      "Epoch: 250 - Loss: 0.7517115540883212\n",
      "Epoch: 300 - Loss: 0.7366967477887703\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(model.embedding_matrix)\n",
    "\n",
    "model = SkipGramModel(\n",
    "    vocab_size=len(tokenizer.vocab), \n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    learning_rate=LR,\n",
    "    target_id=TARGET_ID\n",
    ")\n",
    "\n",
    "train(model, epochs=EPOCHS, training_data=dataset, reducer=pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "**Cosine Similarity**\n",
    "- How we will evaluate our model. We take a pair of words, get their vectors, and check how close they are to eachother. \n",
    "- How close they are to eachother is only considering the angle between the vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "    return similarity\n",
    "\n",
    "def similar_words(model, target_id=0, vector=None, top_k=5):\n",
    "    # Assuming you have a list of words and their corresponding embedding vectors\n",
    "    embedding_matrix = model.embedding_matrix  # Your embedding matrix\n",
    "\n",
    "    # Get the embedding vector of the target word\n",
    "    if vector is None:\n",
    "        target = embedding_matrix[target_id]\n",
    "    else:\n",
    "        target = vector\n",
    "\n",
    "    # Calculate cosine similarity between the target word and all other words\n",
    "    similarities = {}\n",
    "    for index in tokenizer.index_to_key:\n",
    "        if index != target_id:\n",
    "            similarity = cosine_similarity(target, embedding_matrix[index])\n",
    "            similarities[tokenizer.index_to_key[index]] = similarity\n",
    "\n",
    "    # Sort the similar words by their cosine similarity\n",
    "    similar_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the top similar words\n",
    "    if vector is None:\n",
    "        print(\"Similar words for\", tokenizer.index_to_key[target_id])\n",
    "    else:\n",
    "        print(\"Similar words\")\n",
    "    for word, similarity in similar_words[:top_k]:\n",
    "        print(word, \":\", similarity)\n",
    "\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find similar words to \"treasure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words for treasure\n",
      "shore : 0.5202957316988709\n",
      "capture : 0.36898218251248327\n",
      "contexts : 0.36877018420372376\n",
      "secrets : 0.3503871266609803\n",
      "uncover : 0.33499455945018747\n"
     ]
    }
   ],
   "source": [
    "most_similar = similar_words(model, target_id=TARGET_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analog Relationships\n",
    "***\n",
    "Here is a simple example of structuring an analog relationship. We are severly limited by the size of the training corpus, but in large scale applications of this model, really interesting analog relationships can be found.\n",
    "- These are expressed as\n",
    "    - vector2 is to vector3 as vector1 is to?\n",
    "    - The most similar word to this combination will be the answer to this question\n",
    "- Our example:\n",
    "    - Travelers is to Adventures as Hikers is to...\n",
    "        - Good Predictions: (experiences, journey, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words\n",
      "hikers : 0.6255711635853274\n",
      "adventures : 0.5258607787921219\n",
      "sparking : 0.37021114055132415\n",
      "uncovering : 0.3577333836952602\n",
      "laughter : 0.3502359509915714\n",
      "trails : 0.3432787540446172\n",
      "converge : 0.3419726066822966\n",
      "artifacts : 0.34047088078488646\n",
      "wares : 0.30004150594860035\n",
      "bridging : 0.2938428979617964\n"
     ]
    }
   ],
   "source": [
    "vector1 = model.embedding_matrix[tokenizer.key_to_index['hikers']]\n",
    "vector2 = model.embedding_matrix[tokenizer.key_to_index['travelers']]\n",
    "vector3 = model.embedding_matrix[tokenizer.key_to_index['adventures']]\n",
    "\n",
    "analogy_vector = vector1 - vector2 + vector3\n",
    "most_similar = similar_words(model, vector=analogy_vector, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss_curve)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualization\"></a>\n",
    "## Visualizations!\n",
    "To visualize our model, we will get an animation of the word vectors over time, along with the predictions over time. \n",
    "- For the predictions, we compare them against the ground truth. The ground truth is simply the actually percentage of the time that a word appears in the context of our given word. \n",
    "    - Let's say we have the text \"The dog went to the park.\" We are considering the word dog. \n",
    "    - We consider the context \"The\", \"went\"  and \"to\".\n",
    "    - We find that each are in the context 1/3 of the time, because thats the only time we see the word dog. \n",
    "    - In a longer text, we would see dog next to other words, like bone or dig, and the percentage will change. \n",
    "- The visualization provides a beautiful depiction of how the model converges to the correct solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much talked about, but lets see how our loss converges. This shows us how much error the model had throughout training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting colors for our vectors, one per vector so we can easily distinguish the points\n",
    "def generate_unique_colors(num_colors):\n",
    "    cmap = plt.get_cmap('tab20')\n",
    "    return cmap(np.linspace(0, 1, num_colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize vectors over time, we simply select our vectors of choice, and find our model states for these vectors. \n",
    "- Once we do this, we can update our plot every frame to select the vectors at the next time-step. \n",
    "- This gives us the progression of their location in 2D at different times in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_vectors_over_time(vectors_over_time, index_to_key, num_words=20):\n",
    "    plt.ioff()\n",
    "\n",
    "    bound = 2\n",
    "    vectors_to_display = []\n",
    "    # Only select vectors for the first num_words words\n",
    "    for vectors in vectors_over_time:\n",
    "        vectors_shown = [v for i, v in enumerate(vectors[:num_words]) if index_to_key[i] != 'voices']\n",
    "        vectors_to_display.append(vectors_shown)\n",
    "\n",
    "    # Generate unique colors for each word\n",
    "    num_colors = num_words\n",
    "    unique_colors = generate_unique_colors(num_colors)\n",
    "\n",
    "    # Create a figure and axis\n",
    "    # Initialize scatter plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    sc = ax.scatter([], [])\n",
    "\n",
    "    # Set the axis limits\n",
    "    ax.set_xlim(-bound, bound)\n",
    "    ax.set_ylim(-bound, bound)\n",
    "\n",
    "    # Create a list to hold the annotations\n",
    "    annotations = [ax.annotate('', (0, 0)) for _ in range(num_words)]\n",
    "\n",
    "    def update(frame):\n",
    "        # Update the scatter plot data for each frame\n",
    "        sc.set_offsets(vectors_to_display[frame])\n",
    "        sc.set_color(unique_colors[:len(vectors_to_display[frame])])  # Set colors\n",
    "        \n",
    "        # Update annotations with word labels\n",
    "        for i, (x, y) in enumerate(vectors_to_display[frame]):\n",
    "            annotations[i].set_text(index_to_key[i])  # Set word label\n",
    "            annotations[i].set_position((x, y))  # Set position\n",
    "            annotations[i].set_visible(True)  # Make annotation visible\n",
    "\n",
    "        return sc, *annotations\n",
    "\n",
    "    # Create the animation\n",
    "    ani = FuncAnimation(fig, update, frames=len(vectors_to_display), blit=True)\n",
    "\n",
    "    plt.ion()\n",
    "    \n",
    "    return ani\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "ani = visualize_vectors_over_time(model.vectors_over_time, tokenizer.index_to_key, num_words=30)\n",
    "ani.save('../../imgs/vectors.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is our animation, just press play and watch the vectors converge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Vector Animation](../../imgs/vectors.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function simply find every occurence of a given word and find the context distribution we mentioned earlier. This lets us compare both the predictions and ground truth for a given word over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_distribution(dataset, input_id, vocab_size):\n",
    "    context_accumulator = np.zeros(vocab_size)\n",
    "\n",
    "    # Iterate through the corpus data\n",
    "    for sample in dataset:\n",
    "        if sample['input_id'] == input_id:\n",
    "            context_accumulator += np.sum(sample['context'], axis=0)\n",
    "\n",
    "    # Calculate the distribution by normalizing the accumulator\n",
    "    context_distribution = context_accumulator / context_accumulator.sum()\n",
    "\n",
    "    return context_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our predictions, we simply need to update our plot every frame with the prediction at the next iteration. This will simply give us an idea of what the predictions made by the model looked like over time. Since we use gradient descent, you will notice a relatively smooth transition from the initial predictions to the trained predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions_over_time(pred_over_time, y_true, index_to_key, num_words=20):\n",
    "    plt.ioff()\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    lines, = ax.plot([], [], color='red', label='Predicted')\n",
    "    \n",
    "    ax.plot(y_true, color='green', label='Ground Truth')\n",
    "\n",
    "    # Set the axis limits\n",
    "    ax.set_xlim(0, len(index_to_key))\n",
    "    ax.set_ylim(0, 1)  # Assuming context probabilities are between 0 and 1\n",
    "    \n",
    "    # Set labels and legend\n",
    "    ax.set_xlabel('Vocabulary')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title('Predicted vs Ground Truth Probability for \"treasure\"')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    selected_indices = list(np.where(y_true > 0)[0])\n",
    "    selected_labels = [index_to_key[i] for i in selected_indices]\n",
    "\n",
    "    ax.set_xticks(selected_indices)\n",
    "    ax.set_xticklabels(selected_labels, rotation=90)\n",
    "\n",
    "    def update(frame):\n",
    "        prob_list = pred_over_time[frame]\n",
    "        lines.set_data(range(len(prob_list)), prob_list)\n",
    "\n",
    "        return lines,\n",
    "\n",
    "    # Create the animation\n",
    "    ani = FuncAnimation(fig, update, frames=len(pred_over_time), blit=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.ion()\n",
    "\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the truth of which words appear in the context of our word and what percent of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "ground_truth = get_context_distribution(dataset, TARGET_ID, len(tokenizer.vocab))\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "ani = visualize_predictions_over_time(model.predictions_over_time[::10], ground_truth, tokenizer.index_to_key)\n",
    "ani.save('../../imgs/predictions.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our visualization of the predictions!\n",
    "\n",
    "![Vector Animation](../../imgs/predictions.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Projector\n",
    "***\n",
    "Here I write our findings into two tsv files which can be loaded into the [Tensorflow Embedding Projector](https://projector.tensorflow.org/).\n",
    "- This gives us a great visualization of the embeddings and easy comparison of similar words.\n",
    "- Follow the link to [My Projector!](https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/chris-caballero/2e058818e161d7362ae51368afa00eb4/raw/76d86fc5e085ca7a2d34b8e30cf4d73047405369/projector-config.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../../data/embeddings.tsv', model.embedding_matrix, delimiter='\\t')\n",
    "\n",
    "# Save the metadata as a TSV file\n",
    "with open(\"../../data/metadata.tsv\", 'w') as f:\n",
    "    for item in tokenizer.key_to_index:\n",
    "        f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;\">\n",
    "    <div style=\"background-color: white; width: 25%; padding: 20px; margin-left: 20px\">\n",
    "        <p style=\"font-size: 25px; font-weight: 700; text-align: center; color: #b34c69;\">\n",
    "            Similar Words to <em>Adventures</em>\n",
    "        </p>\n",
    "        <hr>\n",
    "        <p style=\"text-align: center\">\n",
    "            <img src=\"../../imgs/similarity.png\" width='100%' height='100%'>\n",
    "        </p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"discussion\"></a>\n",
    "## Discussion\n",
    "Well! That is pretty much it for our implementation. I had a great time refactoring my old code in this process and having a clean notebook showing the results.\n",
    "1. We implemented the data loading and processing, seeing how easy it is to clean our data for training.\n",
    "2. We went in depth into the model architecture and training methods, and actually implemented our model class and trained it!\n",
    "3. Lastly, we visualized our findings, seeing the prediction convergence to the ground truth, watching the word vectors move around and witnessing some interesting analog relationships.\n",
    "\n",
    "***\n",
    "Thanks so much for checking out this notebook! Check out my other works if you are interested, I hope to have in depth project notebooks for all of them at some point!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
